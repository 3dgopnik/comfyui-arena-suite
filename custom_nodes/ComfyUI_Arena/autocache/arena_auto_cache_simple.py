# EN identifiers; RU comments for clarity.
import os
import json
import time
import shutil
from pathlib import Path
from typing import Optional

LABELS: dict[str, str] = {
    "node.autocache": "üÖ∞Ô∏è Arena AutoCache",
    "input.cache_root": "Cache root directory",
    "input.max_size_gb": "Maximum cache size (GB)",
    "input.enable": "Enable AutoCache",
    "input.verbose": "Verbose logging",
    "input.min_size_gb": "Minimum size for caching (GB)",
    "input.skip_hardcoded_paths": "Skip hardcoded paths",
    "input.category": "Model category",
    "input.categories": "Model categories to cache",
}

def t(key: str) -> str:
    """RU: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–ª—é—á—É."""
    return LABELS.get(key, key)

class ArenaCacheSettings:
    """RU: –û—Ç—Ä–∞–∂–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–µ—à–∞ –≤–æ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏."""
    def __init__(self):
        self.root = Path(os.environ.get("ARENA_CACHE_ROOT", "C:/ComfyUI/cache"))
        self.max_gb = max(0, int(os.environ.get("ARENA_CACHE_MAX_GB", "300")))
        self.enable = os.environ.get("ARENA_CACHE_ENABLE", "true").lower() in ("true", "1", "yes", "on")
        self.verbose = os.environ.get("ARENA_CACHE_VERBOSE", "false").lower() in ("true", "1", "yes", "on")
        self.min_size_gb = float(os.environ.get("ARENA_CACHE_MIN_SIZE_GB", "1.0"))
        self.min_size_mb = float(os.environ.get("ARENA_CACHE_MIN_SIZE_MB", "1024.0"))
        self.skip_hardcoded_paths = os.environ.get("ARENA_CACHE_SKIP_HARDCODED", "true").lower() in ("true", "1", "yes", "on")

_settings = ArenaCacheSettings()

if _settings.enable:
    try:
        _settings.root.mkdir(parents=True, exist_ok=True)
    except Exception as root_err:  # pragma: no cover - logging only
        print(f"[ArenaAutoCache] failed to prepare cache root {_settings.root}: {root_err}")

_folder_paths_patched = False
_session_hits = 0
_session_misses = 0

NODE_CLASS_MAPPINGS: dict[str, type] = {}
NODE_DISPLAY_NAME_MAPPINGS: dict[str, str] = {}

def _now() -> float:
    """RU: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö."""
    return time.time()

def _duration_since(started: float) -> float:
    """RU: –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å –º–æ–º–µ–Ω—Ç–∞ started."""
    return _now() - started

def _apply_folder_paths_patch_locked():
    """RU: –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–∞—Ç—á folder_paths –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π."""
    global _folder_paths_patched
    
    if _folder_paths_patched:
        return
    
    try:
        import folder_paths
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—á - –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–µ—à—É
        def patched_get_folder_paths(folder_type: str):
            """RU: –ü–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è get_folder_paths —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
            if not _settings.enable:
                return []
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏
            try:
                original_paths = folder_paths.get_folder_paths(folder_type)
            except:
                original_paths = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–µ—à—É
            cache_path = str(_settings.root / folder_type)
            if cache_path not in original_paths:
                return list(original_paths) + [cache_path]
            return original_paths
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á
        folder_paths.get_folder_paths = patched_get_folder_paths
        _folder_paths_patched = True
        print(f"[ArenaAutoCache] Applied folder_paths patch")
        
    except Exception as e:
        print(f"[ArenaAutoCache] Failed to apply folder_paths patch: {e}")

def _cache_file(folder_type: str, filename: str, source_path: str):
    """RU: –ö–µ—à–∏—Ä—É–µ—Ç —Ñ–∞–π–ª."""
    try:
        source_file = Path(source_path)
        if not source_file.exists():
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size_mb = source_file.stat().st_size / (1024 * 1024)
        if file_size_mb < _settings.min_size_mb:
            if _settings.verbose:
                print(f"[ArenaAutoCache] Skipping small file: {filename} ({file_size_mb:.1f} MB)")
            return False
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –∫–µ—à–∞
        cache_dir = _settings.root / folder_type
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
        cache_file = cache_dir / filename
        if not cache_file.exists():
            if _settings.verbose:
                print(f"[ArenaAutoCache] Caching: {filename}")
            shutil.copy2(source_file, cache_file)
            return True
        
        return True
            
    except Exception as e:
        print(f"[ArenaAutoCache] Error caching {filename}: {e}")
        return False

class ArenaAutoCache:
    """RU: –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –Ω–æ–¥–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π.

    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—É—â–µ–º workflow –∏ –∫–µ—à–∏—Ä—É–µ—Ç –∏—Ö.
    –û–¥–Ω–∞ –Ω–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è.
    """

    @classmethod
    def INPUT_TYPES(cls):  # noqa: N802
        return {
            "required": {},
            "optional": {
                "categories": (
                    "STRING",
                    {
                        "default": "checkpoints,loras,vaes,upscale_models,controlnet",
                        "description": "Model categories to cache",
                        "tooltip": "Comma-separated list of model categories to automatically cache",
                    },
                ),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("result",)
    RETURN_DESCRIPTIONS = ("Cache operation result",)
    OUTPUT_TOOLTIPS = ("Shows which models were cached",)
    FUNCTION = "run"
    CATEGORY = "Arena/AutoCache"
    DESCRIPTION = "Automatically cache models from current workflow"
    OUTPUT_NODE = True

    def run(
        self,
        categories: str = "checkpoints,loras,vaes,upscale_models,controlnet"
    ):
        """Automatically detect and cache models from current workflow."""
        print("[ArenaAutoCache] Starting automatic model detection and caching")
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø–∞—Ç—á –ø—É—Ç–µ–π –∞–∫—Ç–∏–≤–µ–Ω
        _apply_folder_paths_patch_locked()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π canvas –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
        found_models = self._analyze_current_canvas(categories)
        
        if not found_models:
            print("[ArenaAutoCache] No models found in current canvas")
            return json.dumps({
                "ok": False,
                "message": "No models found in current canvas",
                "details": [
                    "Add model loading nodes to your canvas first",
                    "Use Load Checkpoint, Load VAE, or other model nodes"
                ]
            }, ensure_ascii=False, indent=2)
        
        print(f"[ArenaAutoCache] Found {len(found_models)} models in current canvas")
        
        # –ö–µ—à–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        print(f"[ArenaAutoCache] Starting cache process for {len(found_models)} models")
        cache_results = self._cache_models_with_progress(found_models)
        print(f"[ArenaAutoCache] Cache process completed. Results: {len(cache_results)}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        cached_count = len([r for r in cache_results if r["status"] == "cached"])
        skipped_count = len([r for r in cache_results if r["status"].startswith("skipped")])
        error_count = len([r for r in cache_results if r["status"] in ["error", "not_found"]])
        
        result = {
            "ok": True,
            "message": f"Successfully processed {len(found_models)} models",
            "models_found": len(found_models),
            "cached": cached_count,
            "skipped": skipped_count,
            "errors": error_count,
            "categories_checked": [cat.strip() for cat in categories.split(",")],
            "models": found_models,
            "cache_results": cache_results,
        }
        
        return json.dumps(result, ensure_ascii=False, indent=2)

    def _analyze_current_canvas(self, categories: str) -> list[dict]:
        """RU: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â–∏–π canvas –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π."""
        categories_list = [cat.strip() for cat in categories.split(",")]
        found_models = []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞–ø–∫–∏ —Å –º–æ–¥–µ–ª—è–º–∏
            from folder_paths import get_folder_paths
            model_folders = get_folder_paths()
            
            # –ò—â–µ–º –º–æ–¥–µ–ª–∏ –≤ –ø–∞–ø–∫–∞—Ö
            for category in categories_list:
                if category in model_folders:
                    category_path = Path(model_folders[category])
                    if category_path.exists():
                        for model_file in category_path.iterdir():
                            if model_file.is_file() and model_file.suffix.lower() in ['.ckpt', '.safetensors', '.pt', '.pth', '.bin']:
                                found_models.append({
                                    "name": model_file.name,
                                    "category": category,
                                    "path": str(model_file),
                                    "size_mb": model_file.stat().st_size / (1024 * 1024)
                                })
            
            return found_models
            
        except Exception as e:
            print(f"[ArenaAutoCache] Error analyzing canvas: {e}")
            return []

    def _cache_models_with_progress(self, models: list[dict]) -> list[dict]:
        """RU: –ö–µ—à–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞."""
        results = []
        
        for model in models:
            try:
                success = _cache_file(model["category"], model["name"], model["path"])
                if success:
                    results.append({
                        "name": model["name"],
                        "status": "cached",
                        "message": f"Cached successfully ({model['size_mb']:.1f} MB)"
                    })
                else:
                    results.append({
                        "name": model["name"],
                        "status": "skipped",
                        "message": "Already cached or too small"
                    })
                
            except Exception as e:
                results.append({
                    "name": model["name"],
                    "status": "error",
                    "message": f"Error: {str(e)}"
                })
        
        return results

# –í–µ—Ä—Å–∏—è –Ω–æ–¥
ARENA_NODES_VERSION = "v2.23"

NODE_CLASS_MAPPINGS.update(
    {
        # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –Ω–æ–¥–∞ Arena AutoCache - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
        "ArenaAutoCache": ArenaAutoCache,
        f"ArenaAutoCache {ARENA_NODES_VERSION}": ArenaAutoCache,
    }
)

NODE_DISPLAY_NAME_MAPPINGS.update(
    {
        # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –Ω–æ–¥–∞ Arena AutoCache - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
        "ArenaAutoCache": "üÖ∞Ô∏è Arena AutoCache",
        f"ArenaAutoCache {ARENA_NODES_VERSION}": f"üÖ∞Ô∏è Arena AutoCache {ARENA_NODES_VERSION}",
    }
)
